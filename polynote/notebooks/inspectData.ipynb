{
  "metadata" : {
    "config" : {
      "dependencies" : {
        
      },
      "exclusions" : [
      ],
      "repositories" : [
      ],
      "sparkConfig" : {
        "spark.ui.port" : "4140",
        "spark.sql.catalog.spark_catalog" : "org.apache.spark.sql.delta.catalog.DeltaCatalog",
        "spark.hadoop.javax.jdo.option.ConnectionDriverName" : "org.apache.derby.jdbc.ClientDriver",
        "spark.hadoop.javax.jdo.option.ConnectionPassword" : "1234",
        "spark.hadoop.javax.jdo.option.ConnectionURL" : "jdbc:derby://metastore:1527/db;create=true",
        "spark.hadoop.javax.jdo.option.ConnectionUserName" : "sa",
        "spark.sql.extensions" : "io.delta.sql.DeltaSparkSessionExtension"
      },
      "env" : {
        
      }
    },
    "language_info" : {
      "name" : "scala"
    }
  },
  "nbformat" : 4,
  "nbformat_minor" : 0,
  "cells" : [
    {
      "cell_type" : "markdown",
      "execution_count" : 0,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "# Airport Data Inspector\n",
        "\n",
        "\n",
        "Polynote provide the possibility to work with the data using: SQL, Scala, Python, or VegaSpec.\n",
        "\n",
        "In this notebook we have a first look to our data. These notebooks are also very handy to develop new queries or transformation before applying them to the pipeline.<br>\n",
        "\n",
        "\n",
        "First list the table catalog:\n",
        "\n",
        "\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 1,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1656494854081,
          "endTs" : 1656494860897
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "spark.catalog.listTables.show(false)"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "markdown",
      "execution_count" : 8,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "Let's inspect the structure of one table, let's say the int_departures table. <div>Then list the content (at least a few lines).</div>"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 2,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1656495017944,
          "endTs" : 1656495018810
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val df_dep = spark.table(\"default.int_departures\")\r\n",
        "df_dep.printSchema"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 3,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1656495019462,
          "endTs" : 1656495022675
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "df_dep.show()"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "markdown",
      "execution_count" : 9,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "Check the amount of rows downloaded per airport and the latest date. "
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 5,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1656764833962,
          "endTs" : 1656764837028
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "import org.apache.spark.sql.functions.{min, max, count}\r\n",
        "import org.apache.spark.sql.Row\r\n",
        "\r\n",
        "val count = df_dep.count()\r\n",
        "\r\n",
        "import org.apache.spark.sql.functions._\r\n",
        "//df_dep.groupBy($\"estDepartureAirport\").agg(min(\"dt\").as(\"earlist\"), max(\"dt\").as(\"latest\") ).show()\r\n",
        "df_dep.groupBy($\"estDepartureAirport\").agg(Map(\"icao24\"->\"count\", \"dt\"->\"max\") ).show()"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 6,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1656764025116,
          "endTs" : 1656764025763
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 7,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1656764025116,
          "endTs" : 1656764025763
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
      ],
      "outputs" : [
      ]
    }
  ]
}