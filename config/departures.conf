dataObjects {

  ext-departures {
    type = CustomWebserviceDataObject
    schema = """array< struct< icao24: string, firstSeen: integer, estDepartureAirport: string, lastSeen: integer, estArrivalAirport: string, callsign: string, estDepartureAirportHorizDistance: integer, estDepartureAirportVertDistance: integer, estArrivalAirportHorizDistance: integer, estArrivalAirportVertDistance: integer, departureAirportCandidatesCount: integer, arrivalAirportCandidatesCount: integer >>"""
    baseUrl = "https://opensky-network.org/api/flights/departure"
    nRetry = 5
    queryParameters = [{
      airport = "LSZB"
      begin = 1630200800
      end = 1630310979
    },{
      airport = "EDDF"
      begin = 1630200800
      end = 1630310979
    }]
    timeouts {
      connectionTimeoutMs = 200000
      readTimeoutMs = 200000
    }
  }

  int-departures {
    type = DeltaLakeTableDataObject
    path = "~{id}"
    table {
      db = "default"
      name = "int_departures"
      primaryKey = [icao24, estdepartureairport, dt]
    }
  }
}

actions {
  download-deduplicate-departures {
    type = DeduplicateAction
    inputId = ext-departures
    outputId = int-departures
    executionMode = { type = DataObjectStateIncrementalMode }
    mergeModeEnable = true
    updateCapturedColumnOnlyWhenChanged = true
    transformers = [{
      type = SQLDfTransformer
      code = "select ext_departures.*, date_format(from_unixtime(firstseen),'yyyyMMdd') dt from ext_departures"
    },{
      type = ScalaCodeSparkDfTransformer
      code = """
        import org.apache.spark.sql.{DataFrame, SparkSession}
        def transform(session: SparkSession, options: Map[String,String], df: DataFrame, dataObjectId: String) : DataFrame = {
          import session.implicits._
          df.dropDuplicates("icao24", "estdepartureairport", "dt")
        }
        // return as function
        transform _
      """
    }]
    metadata {
      feed = compute
    }
  }
}
